{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecca5efa",
   "metadata": {},
   "source": [
    "# CAEM-GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c12b79",
   "metadata": {},
   "source": [
    "CAEM-GBDT: a cancer subtype identifying method using Multi-omics data and convolutional autoencoder network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc1d98f",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd56e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv1D,Conv1DTranspose,BatchNormalization,Activation,multiply,MaxPool1D,Dropout,GRU,Flatten,Dense,UpSampling1D\n",
    "from tensorflow.keras import Model,datasets\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from keras import losses\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import os\n",
    "import tensorflow.keras.backend as kb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "import warnings\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.svm as svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb4aad",
   "metadata": {},
   "source": [
    "# loading data and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('E:/多组学数据/datasets/txt/Breast/Breast_gene.txt',dtype=np.str)\n",
    "data = np.array(data).astype(np.float32)\n",
    "data.mean(axis=1)\n",
    "data = data - data.mean(axis=0,keepdims=True)\n",
    "data = data / np.sqrt(data.var(axis=0,keepdims = True))\n",
    "data.var(axis=0)\n",
    "\n",
    "\n",
    "data1 = np.loadtxt('E:/多组学数据/datasets/txt/Breast/Breast_Methy.txt',dtype=np.str)\n",
    "data1 = np.array(data1).astype(np.float32)\n",
    "data1.mean(axis=1)\n",
    "data1 = data1 - data1.mean(axis=0,keepdims=True)\n",
    "data1 = data1 / np.sqrt(data1.var(axis=0,keepdims = True))\n",
    "data1.var(axis=0)\n",
    "\n",
    "\n",
    "data2 = np.loadtxt('E:/多组学数据/datasets/txt/Breast/Breast_Mirna.txt',dtype=np.str)\n",
    "data2 = np.array(data2).astype(np.float32)\n",
    "data2.mean(axis=1)\n",
    "data2 = data2 - data2.mean(axis=0,keepdims=True)\n",
    "data2 = data2 / np.sqrt(data2.var(axis=0,keepdims = True))\n",
    "data2.var(axis=0)\n",
    "\n",
    "\n",
    "Data = tf.concat([data,data1,data2],axis=1)\n",
    "Data = np.array(Data)\n",
    "Data.mean(axis=1)\n",
    "Data = Data - Data.mean(axis=0,keepdims=True)\n",
    "Data = Data / np.sqrt(Data.var(axis=0,keepdims = True))\n",
    "Data.var(axis=0)\n",
    "Data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cf6e9",
   "metadata": {},
   "source": [
    "(104,41262)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = np.loadtxt('E:/多组学数据/datasets/txt/Breast/Breast_Label.txt',dtype=np.str)\n",
    "tag = np.array(tag).astype(np.float32)\n",
    "tag.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88c73f",
   "metadata": {},
   "source": [
    "(104,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f046cd",
   "metadata": {},
   "source": [
    "# Gelu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a483cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "            return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c654a",
   "metadata": {},
   "source": [
    "# convolutional block attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_block(cbam_feature, ratio=8,kernel_size = 3):\n",
    "\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature,kernel_size)\n",
    "    return cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "\n",
    "    channel = input_feature.shape[-1]\n",
    "    filters = max(1, int(channel//ratio))\n",
    "    shared_layer_one = tf.keras.layers.Dense(filters,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = tf.keras.layers.Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "\n",
    "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(input_feature)    \n",
    "    avg_pool = tf.keras.layers.Reshape((1,1,channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(input_feature)\n",
    "    max_pool = tf.keras.layers.Reshape((1,1,channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "   \n",
    "\n",
    "    cbam_feature = tf.keras.layers.Add()([avg_pool,max_pool])\n",
    "    cbam_feature = tf.keras.layers.Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "def spatial_attention(input_feature,kernel_siz):\n",
    "    kernel_size = kernel_siz\n",
    "\n",
    "    channel = input_feature.shape[-1]\n",
    "    cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    max_pool = tf.keras.layers.Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    concat = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    cbam_feature = tf.keras.layers.Conv1D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)\t\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5eea3",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        super (MyModel,self).__init__()\n",
    "        #expression\n",
    "        self.f1 = tf.keras.layers.Dense(512,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        self.f2 = tf.keras.layers.Conv1D(filters = 16,kernel_size = 3,padding='same',strides = 2,activation=gelu)\n",
    "        self.f3 = tf.keras.layers.MaxPool1D(pool_size = 2)\n",
    "        self.f4 = tf.keras.layers.Conv1D(filters = 4,kernel_size = 3,padding='same',strides = 2,activation=gelu)\n",
    "        self.f5 = tf.keras.layers.MaxPool1D(pool_size = 4)\n",
    "        self.f6 = tf.keras.layers.Conv1DTranspose(filters = 4,kernel_size = 3,padding='same',strides =2,activation=gelu)\n",
    "        self.f7 = tf.keras.layers.UpSampling1D(size = 4)\n",
    "        self.f8 = tf.keras.layers.Conv1DTranspose(filters = 16,kernel_size = 3,padding='same',strides =2,activation=gelu)\n",
    "        self.f9 = tf.keras.layers.UpSampling1D(size = 2)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.f10 = tf.keras.layers.Dense(512,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        self.f11 = tf.keras.layers.Dense(17814,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        \n",
    "        #methy\n",
    "        self.f12 = tf.keras.layers.Dense(512,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        self.f13 = tf.keras.layers.Conv1D(filters = 16,kernel_size = 3,padding='same',strides = 2,activation=gelu)\n",
    "        self.f14 = tf.keras.layers.MaxPool1D(pool_size = 2)\n",
    "        self.f15 = tf.keras.layers.Conv1D(filters = 4,kernel_size = 3,padding='same',strides = 2,activation=gelu)\n",
    "        self.f16 = tf.keras.layers.MaxPool1D(pool_size = 4)\n",
    "        self.f17 = tf.keras.layers.Conv1DTranspose(filters = 4,kernel_size = 3,padding='same',strides =2,activation=gelu)\n",
    "        self.f18 = tf.keras.layers.UpSampling1D(size = 4)\n",
    "        self.f19 = tf.keras.layers.Conv1DTranspose(filters = 16,kernel_size = 3,padding='same',strides =2,activation=gelu)\n",
    "        self.f20 = tf.keras.layers.UpSampling1D(size = 2)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.f21 = tf.keras.layers.Dense(512,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        self.f22 = tf.keras.layers.Dense(23094,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        \n",
    "        #mRNA\n",
    "        self.f23 = tf.keras.layers.Dense(128,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        self.f24 = tf.keras.layers.Conv1D(filters = 4,kernel_size = 3,padding='same',strides = 2,activation=gelu)\n",
    "        self.f25 = tf.keras.layers.MaxPool1D(pool_size = 4)\n",
    "        self.f26 = tf.keras.layers.Conv1DTranspose(filters = 4,kernel_size = 3,padding='same',strides =2,activation=gelu)\n",
    "        self.f27 = tf.keras.layers.UpSampling1D(size = 4)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.f28 = tf.keras.layers.Dense(128,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        self.f29 = tf.keras.layers.Dense(354,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "    def call(self,x):\n",
    "        input1 = x[:,0:17814]\n",
    "        input2 = x[:,17814:40908]\n",
    "        input3 = x[:,40908:]\n",
    "        #expression\n",
    "        x = self.f1(input1)\n",
    "        x = Reshape((512,1))(x)\n",
    "        x = self.f2(x)\n",
    "        x = self.f3(x)\n",
    "        x = self.f4(x)\n",
    "        encode1 = self.f5(x)\n",
    "        x = self.f6(encode1)\n",
    "        x = self.f7(x)\n",
    "        x = self.f8(x)\n",
    "        x = self.f9(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.f10(x)\n",
    "        decode1 = self.f11(x)\n",
    "        \n",
    "        #methy\n",
    "        x = self.f12(input2)\n",
    "        x = Reshape((512,1))(x)\n",
    "        x = self.f13(x)\n",
    "        x = self.f14(x)\n",
    "        x = self.f15(x)\n",
    "        encode2 = self.f16(x)\n",
    "        x = self.f17(encode2)\n",
    "        x = self.f18(x)\n",
    "        x = self.f19(x)\n",
    "        x = self.f20(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.f21(x)\n",
    "        decode2 = self.f22(x)\n",
    "        \n",
    "        #mRNA\n",
    "        x = self.f23(input3)\n",
    "        x = Reshape((128,1))(x)\n",
    "        x = self.f24(x)\n",
    "        encode3 = self.f25(x)\n",
    "        x = self.f26(encode3)\n",
    "        x = self.f27(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.f28(x)\n",
    "        decode3 = self.f29(x)\n",
    "        z = tf.concat([encode1,encode2,encode3],axis=1)\n",
    "        c = cbam_block(z)\n",
    "        d = self.flatten(c)\n",
    "        return d,decode1,decode2,decode3\n",
    "    \n",
    "    \n",
    "model = MyModel()\n",
    "model.build(input_shape=(104,41262))\n",
    "model.call(Input(shape=(41262,)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1227e",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750effbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits,gene,methy,mrna = model(x, training=True)\n",
    "        recon_loss1 = losses.mean_squared_error(x[:,0:17814],gene)\n",
    "        recon_loss2 = losses.mean_squared_error(x[:,17814:40908],methy)\n",
    "        recon_loss3 = losses.mean_squared_error(x[:,40908:],mrna)\n",
    "        loss_value = recon_loss1 + recon_loss2 + recon_loss3\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    return loss_value,logits\n",
    "\n",
    "\n",
    "def val_step(x, y):\n",
    "    val_logits,gene,methy,mrna = model(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4)\n",
    "epos = 100\n",
    "for epo in range(epos):\n",
    "    print(\"\\nStart of epoch %d\" % (epo,))\n",
    "    loss,log=train_step(data[0:78,:], tag[0:78])\n",
    "    log = np.array(log)\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(log,tag[0:78],test_size=0.25,random_state=20)\n",
    "    \n",
    "    #modelknn=KNeighborsClassifier(n_neighbors=10)\n",
    "    #modelknn.fit(X_train,y_train)\n",
    "    #y_pred = modelknn.predict(X_test)\n",
    "    \n",
    "    #modeldeep = CascadeForestClassifier(random_state=0)\n",
    "    #modeldeep.fit(X_train,y_train)\n",
    "    #y_pred = modeldeep.predict(X_test)\n",
    "    \n",
    "    #modelrf = RandomForestClassifier(random_state=0)\n",
    "    #modelrf.fit(X_train,y_train)\n",
    "    #y_pred = modelrf.predict(X_test)\n",
    "    \n",
    "    #modelsvm = svm.SVC(kernel='linear',probability=True,random_state=20)\n",
    "    #modelsvm.fit(X_train,y_train)\n",
    "    #y_pred = modelsvm.predict(X_test)\n",
    "    \n",
    "    gbm= GradientBoostingClassifier(learning_rate=0.1,n_estimators=300,max_depth=3,min_samples_leaf =5, min_samples_split =5, max_features='sqrt',subsample=0.8,random_state=10)\n",
    "    gbm.fit(X_train,y_train)\n",
    "    y_pred = gbm.predict(X_test)\n",
    "\n",
    " \n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    f1 = f1_score(y_test,y_pred, average='macro' )\n",
    "    p = precision_score(y_test,y_pred, average='macro')\n",
    "    r = recall_score(y_test,y_pred, average='macro')\n",
    "    \n",
    "    print(\"accuracy: %.3f\" % (float(accuracy),))\n",
    "    print(\"Precision：%.3f\",p)\n",
    "    print(\"Recall：%.3f\",r)\n",
    "    print(\"F1：%.3f\",f1)\n",
    " \n",
    "\n",
    "\n",
    "    val_step(data[78:,:], tag[78:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0afc9",
   "metadata": {},
   "source": [
    "Start of epoch 21\n",
    "accuracy: 0.950\n",
    "Precision： 0.976\n",
    "Recall： 0.889\n",
    "F1： 0.930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a600e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
