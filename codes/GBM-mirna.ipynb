{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecca5efa",
   "metadata": {},
   "source": [
    "# CAEM-GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c12b79",
   "metadata": {},
   "source": [
    "CAEM-GBDT: a cancer subtype identifying method using Multi-omics data and convolutional autoencoder network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc1d98f",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd56e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv1D,Conv1DTranspose,BatchNormalization,Activation,multiply,MaxPool1D,Dropout,GRU,Flatten,Dense,UpSampling1D\n",
    "from tensorflow.keras import Model,datasets\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from keras import losses\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import os\n",
    "import tensorflow.keras.backend as kb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "import warnings\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.svm as svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb4aad",
   "metadata": {},
   "source": [
    "# loading data and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.loadtxt('E:/多组学数据/datasets/txt/GBM/GBM_Mirna.txt',dtype=np.str)\n",
    "data2 = np.array(data).astype(np.float32)\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cf6e9",
   "metadata": {},
   "source": [
    "(213,534)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = np.loadtxt('E:/多组学数据/datasets/txt/GBM/GBM_Label.txt',dtype=np.str)\n",
    "tag = np.array(tag).astype(np.float32)\n",
    "tag.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88c73f",
   "metadata": {},
   "source": [
    "(213,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f046cd",
   "metadata": {},
   "source": [
    "Gelu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a483cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "            return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c654a",
   "metadata": {},
   "source": [
    "# convolutional block attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_block(cbam_feature, ratio=8,kernel_size = 3):\n",
    "\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature,kernel_size)\n",
    "    return cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "\n",
    "    channel = input_feature.shape[-1]\n",
    "    filters = max(1, int(channel//ratio))\n",
    "    shared_layer_one = tf.keras.layers.Dense(filters,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = tf.keras.layers.Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "\n",
    "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(input_feature)    \n",
    "    avg_pool = tf.keras.layers.Reshape((1,1,channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(input_feature)\n",
    "    max_pool = tf.keras.layers.Reshape((1,1,channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "   \n",
    "\n",
    "    cbam_feature = tf.keras.layers.Add()([avg_pool,max_pool])\n",
    "    cbam_feature = tf.keras.layers.Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "def spatial_attention(input_feature,kernel_siz):\n",
    "    kernel_size = kernel_siz\n",
    "\n",
    "    channel = input_feature.shape[-1]\n",
    "    cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    max_pool = tf.keras.layers.Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    concat = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    cbam_feature = tf.keras.layers.Conv1D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)\t\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5eea3",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        super (MyModel,self).__init__()\n",
    "        self.f1 = tf.keras.layers.Dense(128,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        self.f2 = tf.keras.layers.Conv1D(filters = 4,kernel_size = 3,padding='same',strides = 2,activation=gelu)\n",
    "        self.f3 = tf.keras.layers.MaxPool1D(pool_size = 4)\n",
    "        self.f8 = tf.keras.layers.Conv1DTranspose(filters = 4,kernel_size = 3,padding='same',strides =2,activation=gelu)\n",
    "        self.f9 = tf.keras.layers.UpSampling1D(size = 4)\n",
    "        self.f12 = tf.keras.layers.Conv1DTranspose(filters = 1,kernel_size = 3,padding='same',activation=gelu)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.f11 = tf.keras.layers.Dense(534,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "    def call(self,x):\n",
    "        x = self.f1(x)\n",
    "        x = Reshape((128,1))(x)\n",
    "        x = self.f2(x)\n",
    "        encode = self.f3(x)\n",
    "        a = cbam_block(encode)\n",
    "        x = Reshape((16,4))(a)\n",
    "        c = self.flatten(x)\n",
    "        x = self.f8(encode)\n",
    "        x = self.f9(x)\n",
    "        x = self.f12(x)\n",
    "        x = self.flatten(x)\n",
    "        decode = self.f11(x)\n",
    "        z = tf.concat([c,decode],axis=1)\n",
    "        return z\n",
    "    \n",
    "    \n",
    "model = MyModel()\n",
    "model.build(input_shape=(213,534))\n",
    "model.call(Input(shape=(534,)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1227e",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750effbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        recon_loss = losses.mean_squared_error(x,logits[:,64:])\n",
    "        loss_value = recon_loss\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss_value,logits[:,64:]\n",
    "\n",
    "\n",
    "def val_step(x, y):\n",
    "    val_logits = model(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4)\n",
    "epos = 100\n",
    "\n",
    "for epo in range(epos):\n",
    "    print(\"\\nStart of epoch %d\" % (epo,))\n",
    "    loss,log=train_step(data2[0:170,:], tag[0:170])\n",
    "    log = np.array(log)\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(log,tag[0:170],test_size=0.2,random_state=20)\n",
    "    \n",
    "    #modelknn=KNeighborsClassifier(n_neighbors=10)\n",
    "    #modelknn.fit(X_train,y_train)\n",
    "    #y_pred = modelknn.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #modeldeep = CascadeForestClassifier(random_state=0)\n",
    "    #modeldeep.fit(X_train,y_train)\n",
    "    #y_pred = modedeep.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #modelrf = RandomForestClassifier(random_state=0)\n",
    "    #modelrf.fit(X_train,y_train)\n",
    "    #y_pred = modelrf.predict(X_test)\n",
    "    \n",
    "    #modelsvm = svm.SVC(kernel='linear',probability=True,random_state=20)\n",
    "    #modelsvm.fit(X_train,y_train)\n",
    "    #y_pred = modelsvm.predict(X_test)\n",
    "      \n",
    "    gbm= GradientBoostingClassifier(learning_rate=0.1,n_estimators=300,max_depth=3,min_samples_leaf =5, min_samples_split =5, max_features='sqrt',subsample=0.8,random_state=10)\n",
    "    gbm.fit(X_train,y_train)\n",
    "    y_pred = gbm.predict(X_test)\n",
    " \n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    f1 = f1_score(y_test,y_pred, average='macro' )\n",
    "    p = precision_score(y_test,y_pred, average='macro')\n",
    "    r = recall_score(y_test,y_pred, average='macro')\n",
    "\n",
    "    print(\"accuracy: %.3f\" % (float(accuracy),))\n",
    "    print(\"Precision：%.3f\",p)\n",
    "    print(\"Recall：%.3f\",r)\n",
    "    print(\"F1：%.3f\",f1)\n",
    " \n",
    "\n",
    "    val_step(data2[170:,:], tag[170:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0afc9",
   "metadata": {},
   "source": [
    "Start of epoch 13\n",
    "accuracy: 0.618\n",
    "Precision： 0.541\n",
    "Recall： 0.573\n",
    "F1： 0.557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a600e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
