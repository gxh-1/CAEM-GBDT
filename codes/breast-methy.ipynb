{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecca5efa",
   "metadata": {},
   "source": [
    "# CAEM-GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c12b79",
   "metadata": {},
   "source": [
    "CAEM-GBDT: a cancer subtype identifying method using Multi-omics data and convolutional autoencoder network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc1d98f",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd56e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv1D,Conv1DTranspose,BatchNormalization,Activation,multiply,MaxPool1D,Dropout,GRU,Flatten,Dense,UpSampling1D\n",
    "from tensorflow.keras import Model,datasets\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from keras import losses\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import os\n",
    "import tensorflow.keras.backend as kb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "import warnings\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.svm as svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from deepforest import CascadeForestClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb4aad",
   "metadata": {},
   "source": [
    "# loading data and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.loadtxt('E:/多组学数据/datasets/txt/Breast/Breast_Methy.txt',dtype=np.str)\n",
    "data1 = np.array(data1).astype(np.float32)\n",
    "\n",
    "data1.mean(axis=1)\n",
    "data1 = data1 - data1.mean(axis=0,keepdims=True)\n",
    "data1 = data1 / np.sqrt(data1.var(axis=0,keepdims = True))\n",
    "data1.var(axis=0)\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cf6e9",
   "metadata": {},
   "source": [
    "(104,23094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = np.loadtxt('E:/多组学数据/datasets/txt/Breast/Breast_Label.txt',dtype=np.str)\n",
    "tag = np.array(tag).astype(np.float32)\n",
    "tag.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88c73f",
   "metadata": {},
   "source": [
    "(104,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f046cd",
   "metadata": {},
   "source": [
    "Gelu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a483cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "            return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c654a",
   "metadata": {},
   "source": [
    "# convolutional block attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_block(cbam_feature, ratio=8,kernel_size = 3):\n",
    "\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature,kernel_size)\n",
    "    return cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "\n",
    "    #channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[-1]\n",
    "    filters = max(1, int(channel//ratio))\n",
    "    shared_layer_one = tf.keras.layers.Dense(filters,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = tf.keras.layers.Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "\n",
    "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(input_feature)    \n",
    "    avg_pool = tf.keras.layers.Reshape((1,1,channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(input_feature)\n",
    "    max_pool = tf.keras.layers.Reshape((1,1,channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "   \n",
    "\n",
    "    cbam_feature = tf.keras.layers.Add()([avg_pool,max_pool])\n",
    "    cbam_feature = tf.keras.layers.Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "def spatial_attention(input_feature,kernel_siz):\n",
    "    kernel_size = kernel_siz\n",
    "\n",
    "    channel = input_feature.shape[-1]\n",
    "    cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    #assert avg_pool._keras_shape[-1] == 1\n",
    "    max_pool = tf.keras.layers.Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    #assert max_pool._keras_shape[-1] == 1\n",
    "    concat = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    #assert concat._keras_shape[-1] == 2\n",
    "    cbam_feature = tf.keras.layers.Conv1D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)\t\n",
    "    #assert cbam_feature._keras_shape[-1] == 1\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5eea3",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        super (MyModel,self).__init__()\n",
    "        #self.f5 = tf.keras.layers.Flatten()\n",
    "        self.f1 = tf.keras.layers.Dense(512,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        self.f2 = tf.keras.layers.Conv1D(filters = 16,kernel_size = 3,padding='same',strides = 2,activation=gelu)\n",
    "        self.f3 = tf.keras.layers.MaxPool1D(pool_size = 2)\n",
    "        self.f4 = tf.keras.layers.Conv1D(filters = 4,kernel_size = 3,padding='same',strides = 2,activation=gelu)\n",
    "        self.f5 = tf.keras.layers.MaxPool1D(pool_size = 4)\n",
    "        #self.att = MultiHeadAttention(head_num = 2)\n",
    "        #self.at = SeqSelfAttention(attention_width=15,attention_activation=gelu,attention_regularizer_weight=1e-4)\n",
    "        #self.l1 = tf.keras.layers.GRU(4,return_sequences = True,bias_regularizer=tf.keras.regularizers.l2(1e-4),activity_regularizer=tf.keras.regularizers.l2(1e-5))\n",
    "        \n",
    "        \n",
    "        self.f6 = tf.keras.layers.Conv1DTranspose(filters = 4,kernel_size = 3,padding='same',strides =2,activation=gelu)\n",
    "        self.f7 = tf.keras.layers.UpSampling1D(size = 4)\n",
    "        self.f8 = tf.keras.layers.Conv1DTranspose(filters = 16,kernel_size = 3,padding='same',strides =2,activation=gelu)\n",
    "        self.f9 = tf.keras.layers.UpSampling1D(size = 2)\n",
    "        #self.f12 = tf.keras.layers.Conv1DTranspose(filters = 1,kernel_size = 3,padding='same',activation=gelu)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.f10 = tf.keras.layers.Dense(512,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "        self.f11 = tf.keras.layers.Dense(23094,activation = gelu,kernel_regularizer=tf.keras.regularizers.l2())\n",
    "    def call(self,x):\n",
    "        #x = Reshape((17814,1))(x)\n",
    "        x = self.f1(x)\n",
    "        x = Reshape((512,1))(x)\n",
    "        x = self.f2(x)\n",
    "        x = self.f3(x)\n",
    "        x = self.f4(x)\n",
    "        encode = self.f5(x)\n",
    "        #c = self.flatten(encode)\n",
    "        a = cbam_block(encode)\n",
    "        x = Reshape((16,4))(a)\n",
    "        #c1 = self.at(encode)\n",
    "        #c2 = self.l1(x)\n",
    "        c = self.flatten(x)\n",
    "        x = self.f6(encode)\n",
    "        x = self.f7(x)\n",
    "        x = self.f8(x)\n",
    "        x = self.f9(x)\n",
    "        #x = self.f12(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.f10(x)\n",
    "        decode = self.f11(x)\n",
    "        z = tf.concat([c,decode],axis=1)\n",
    "        return z\n",
    "    \n",
    "    \n",
    "model = MyModel()\n",
    "model.build(input_shape=(104,23094))\n",
    "model.call(Input(shape=(23094,)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1227e",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750effbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        recon_loss = losses.mean_squared_error(x,logits[:,64:])\n",
    "        loss_value = recon_loss\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss_value,logits[:,64:]\n",
    "\n",
    "\n",
    "def val_step(x, y):\n",
    "    val_logits = model(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4)\n",
    "epos = 100\n",
    "\n",
    "for epo in range(epos):\n",
    "    print(\"\\nStart of epoch %d\" % (epo,))\n",
    "    #for x_batch_train, y_batch_train in train_ds:\n",
    "    loss,log=train_step(data[0:83,:], tag[0:83])\n",
    "    log = np.array(log)\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(log,tag[0:83],test_size=0.2,random_state=20)\n",
    "    gbm= GradientBoostingClassifier(learning_rate=0.1,n_estimators=300,max_depth=3,min_samples_leaf =5, min_samples_split =5, max_features='sqrt',subsample=0.8,random_state=10)\n",
    "    #lgb = LGBMClassifier(boosting_type='gbdt',num_leaves=127, learning_rate=0.1, n_estimators=500,objective=multiclass)\n",
    "    #lgb.fit(X_train, y_train)\n",
    "    #modelknn=KNeighborsClassifier(n_neighbors=10)\n",
    "    #modeldeep = CascadeForestClassifier(random_state=0)\n",
    "    #modelrf = RandomForestClassifier(random_state=0)\n",
    "    #modelsvm = svm.SVC(kernel='linear',probability=True,random_state=20)\n",
    "    #mod = xgb.XGBClassifier(n_estimators=500,max_depth=6,min_child_weight = 1,gamma=0.,subsample=0.8,objective='multi:softmax',random_state=27)\n",
    "    gbm.fit(X_train,y_train)\n",
    "    y_pred = gbm.predict(X_test)\n",
    " \n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    f1 = f1_score(y_test,y_pred, average='weighted' )\n",
    "    p = precision_score(y_test,y_pred, average='weighted')\n",
    "    r = recall_score(y_test,y_pred, average='weighted')\n",
    "    print(\"accuracy: %.2f\" % (float(accuracy),))\n",
    "    print(\"Precision：%.2f\",p)\n",
    "    print(\"Recall：%.2f\",r)\n",
    "    print(\"F1：%.2f\",f1)\n",
    " \n",
    "\n",
    "    #for x_batch_val, y_batch_val in val_ds:\n",
    "    val_step(data[83:,:], tag[83:])\n",
    "    #modelsvm2 = svm.SVC(kernel='linear',probability=True,random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0afc9",
   "metadata": {},
   "source": [
    "Start of epoch 36\n",
    "accuracy: 0.82\n",
    "Precision： 0.72\n",
    "Recall： 0.76\n",
    "F1： 0.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a600e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
